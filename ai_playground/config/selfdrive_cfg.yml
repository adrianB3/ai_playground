utils:
  neptune_project: adrianb3/ai-playground # neptune.ai project name
  experiments_dir: D:\repos\ai_playground_experiments # where the experiments data should be stored
  load_exp:  # none is you don't want to load any exp
environment:
  env_path: ../../../ai_playground_build/ai_playground.exe
  time_scale: 4.0 # env time acceleration as multiplication factor over real-time
  behavior_name_high_lvl: abstract_brain?team=0
  behavior_name_low_lvl: primitive_brain?team=0
  behavior_name: CarBrain?team=0
algorithm:
  name: haar
  params:
    ppo:
      optimizer: adam
      optimizer_params:
        adam:
          learning_rate: 0.00004
          epsilon: 0.00001
      ppo_actor_net: actor_preproc
      ppo_value_net: value_preproc
      num_epochs: 5
      discount_factor: 0.995
      gradient_clipping: 0.5
      entropy_regularization: 0.01
      importance_ratio_clipping: 0.2
      use_gae: True
      use_td_lambda_return: True

    haar:
      num_eps: 1000 # N - number of episodes
      k_s: 10 # min number of steps after which a high level action is required
      k_0: 200 # number of low level steps
      num_skills: 2
      j: 3 # number of ep for high level training
      discount_factor_high_lvl: 0.995
      discount_factor_low_lvl: 0.995
      policy_optimizer: ppo
train_session:
  num_env_steps: 300000
  num_parallel_envs: 4
  collect_eps_per_iter: 3
  replay_buff_capacity: 300
  num_eval_episodes: 5
  eval_interval: 2000, # nb of steps between eval sessions
  use_tf_functions: True
  summaries_flush_secs: 1